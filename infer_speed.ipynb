{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "infer_speed.ipynb",
      "provenance": [],
      "mount_file_id": "1In9axspmo0FWBnDvxr8hLKEKTtz8kLF3",
      "authorship_tag": "ABX9TyOtzJoZy40BKZe7B3zBp+Mf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/crystal0523/SVHN-digit-detection/blob/main/infer_speed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkC14hFseGTG"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import cv2\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "!unzip retinanet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJUqIbyRxSFa",
        "outputId": "714653e6-f812-413e-9f0e-2bb1db342349"
      },
      "source": [
        "!unzip retinanet.zip"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  retinanet.zip\n",
            " extracting: retinanet/__init__.py   \n",
            "   creating: retinanet/__pycache__/\n",
            "  inflating: retinanet/__pycache__/__init__.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/__init__.cpython-37.pyc  \n",
            "  inflating: retinanet/__pycache__/anchors.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/anchors.cpython-37.pyc  \n",
            "  inflating: retinanet/__pycache__/coco_eval.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/csv_eval.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/dataloader.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/dataloader.cpython-37.pyc  \n",
            "  inflating: retinanet/__pycache__/losses.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/losses.cpython-37.pyc  \n",
            "  inflating: retinanet/__pycache__/model.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/model.cpython-37.pyc  \n",
            "  inflating: retinanet/__pycache__/utils.cpython-36.pyc  \n",
            "  inflating: retinanet/__pycache__/utils.cpython-37.pyc  \n",
            "  inflating: retinanet/anchors.py    \n",
            "  inflating: retinanet/coco_eval.py  \n",
            "  inflating: retinanet/csv_eval.py   \n",
            "  inflating: retinanet/dataloader.py  \n",
            "  inflating: retinanet/losses.py     \n",
            "  inflating: retinanet/model.py      \n",
            "  inflating: retinanet/oid_dataset.py  \n",
            "  inflating: retinanet/utils.py      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diC8oMq_eNQM",
        "outputId": "ea4e3855-fe11-44f2-98b7-32b5c3206e24"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "import json\n",
        "import cv2\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from timeit import timeit \n",
        "import datetime\n",
        "def load_classes(csv_reader):\n",
        "    result = {}\n",
        "\n",
        "    for line, row in enumerate(csv_reader):\n",
        "        line += 1\n",
        "\n",
        "        try:\n",
        "            class_name, class_id = row\n",
        "        except ValueError:\n",
        "            raise(ValueError('line {}: format should be \\'class_name,class_id\\''.format(line)))\n",
        "        class_id = int(class_id)\n",
        "\n",
        "        if class_name in result:\n",
        "            raise ValueError('line {}: duplicate class name: \\'{}\\''.format(line, class_name))\n",
        "        result[class_name] = class_id\n",
        "    return result\n",
        "\n",
        "image_path='/content/drive/My Drive/73.png'\n",
        "model_path='/content/drive/My Drive/csv_retinanet2_7.pt'\n",
        "class_list='/content/drive/My Drive/class.csv'\n",
        "\n",
        "with open(class_list, 'r') as f:\n",
        "    classes = load_classes(csv.reader(f, delimiter=','))\n",
        "\n",
        "labels = {}\n",
        "for key, value in classes.items():\n",
        "    labels[value] = key\n",
        "\n",
        "model = torch.load(model_path)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "model.training = False\n",
        "model.eval()\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "rows, cols, cns = image.shape\n",
        "\n",
        "smallest_side = min(rows, cols)\n",
        "# rescale the image so the smallest side is min_side\n",
        "min_side = 608\n",
        "max_side = 1024\n",
        "scale = min_side / smallest_side\n",
        "largest_side = max(rows, cols)\n",
        "\n",
        "if largest_side * scale > max_side:\n",
        "    scale = max_side / largest_side\n",
        "\n",
        "# resize the image with the computed scale\n",
        "image = cv2.resize(image, (int(round(cols * scale)), int(round((rows * scale)))))\n",
        "rows, cols, cns = image.shape\n",
        "\n",
        "pad_w = 32 - rows % 32\n",
        "pad_h = 32 - cols % 32\n",
        "\n",
        "new_image = np.zeros((rows + pad_w, cols + pad_h, cns)).astype(np.float32)\n",
        "new_image[:rows, :cols, :] = image.astype(np.float32)\n",
        "image = new_image.astype(np.float32)\n",
        "image /= 255\n",
        "image -= [0.485, 0.456, 0.406]\n",
        "image /= [0.229, 0.224, 0.225]\n",
        "image = np.expand_dims(image, 0)\n",
        "image = np.transpose(image, (0, 3, 1, 2))\n",
        "\n",
        "with torch.no_grad():\n",
        "  image = torch.from_numpy(image)\n",
        "\n",
        "  if torch.cuda.is_available():\n",
        "    image = image.cuda()\n",
        "\n",
        "\n",
        "  def infer(image,model):\n",
        "    scores, classification, transformed_anchors = model(image.cuda().float())\n",
        "\n",
        "\n",
        "  infer(image,model)\n",
        "  %timeit infer(image,model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 93.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "8CVSYBaPzk8H",
        "outputId": "b6439232-128e-4bd2-bdfe-7e15ab07ca97"
      },
      "source": [
        "infer('/content/drive/My Drive/73.png')\n",
        "print('Testing inference time')\n",
        "%timeit infer(image)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ff7660b98008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/73.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing inference time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit infer(image)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-821c8059a52f>\u001b[0m in \u001b[0;36minfer\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# process image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_anchors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fryV9wSFkTvf",
        "outputId": "d5ad2d02-ddeb-435e-9677-663c4c5f5182"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls \"/content/drive/My Drive\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            " 40547040S_黃敏涓_project1.cpp\n",
            " 40547040S_黃敏涓_project1.exe\n",
            " 73.png\n",
            "'Anyfile Notepad Files'\n",
            " class.csv\n",
            "'Colab Notebooks'\n",
            "'Copy of group30_DLP2020_video.mp4'\n",
            "'Copy of 經濟學.docx'\n",
            "'Copy of 經濟學.gdoc'\n",
            " csv_retinanet2_7.pt\n",
            " CV_黃敏涓.pdf\n",
            " Desktop.rar\n",
            "'Enhancing a Pairs Trading strategy with the application_implement.pptx'\n",
            "'Enhancing a Pairs Trading strategy with the application.pptx'\n",
            "'Generative adversarial network based telecom fraud detection at recieving bank.pptx'\n",
            " gesture_recognition\n",
            " GloVe.docx\n",
            "'Google 相簿'\n",
            " group30_DLP2020_intro.mp4\n",
            " L1-Introduction-2018.pdf\n",
            "'L5-MachineLearningBasics-2018 (v2).pdf'\n",
            " MSP微軟學生大使.pptx\n",
            "'National Taiwan Normal University - Gongguan Campus 30.m4a'\n",
            " 交大\n",
            " 報到單.pdf\n",
            "'手機APP 相關'\n",
            " 新生報到表格-論文指導教授初步確認單.doc\n",
            " 穿戴式手套之手勢辨識應用_期末報告.pdf\n",
            " 經濟學.docx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiyTkKBWejpt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}